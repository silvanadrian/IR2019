{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.preprocessing import normalize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import subprocess\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from nltk.corpus import stopwords\n",
    "#import unidecode\n",
    "\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home'\n",
    "\n",
    "import jnius_config\n",
    "jnius_config.set_classpath(\"/Users/silvan/ucph/Block4-19/IR2019/assignments/assignment_2/anserini/target/anserini-0.5.1-SNAPSHOT-fatjar.jar\")\n",
    "\n",
    "from jnius import autoclass\n",
    "JString = autoclass('java.lang.String')\n",
    "JSearcher = autoclass('io.anserini.search.SimpleSearcher')\n",
    "\n",
    "searcher = JSearcher(JString('/Users/silvan/ucph/Block4-19/IR2019/assignments/assignment_2/anserini/lucene-index.robust04.pos+docvectors+rawdocs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads the file into one big string\n",
    "with open('04.testset', 'r') as file:\n",
    "    data = file.read()\n",
    "    \n",
    "#regular expressions for pulling out the querys and their id's     \n",
    "idreg = re.compile('<num.*\\s(\\d+)')\n",
    "qid = re.findall(idreg, data)\n",
    "\n",
    "titreg = re.compile('<title>\\s(.+)')\n",
    "qry = re.findall(titreg, data)\n",
    "\n",
    "qrys = list(zip(qid,qry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the GLoVe word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.74\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format('glove/glove.6B.300d.w2vformat.txt')\n",
    "\n",
    "end = time.time()\n",
    "print(round(end - start,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for basic BM25 + TREC_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ranking(inp, fixed= 'Q0', run='BM25run', runlen = 1000):\n",
    "        qid, qry = inp\n",
    "        hits = searcher.search(JString(qry), runlen)\n",
    "        scores, docids = [h.score for h in hits], [h.docid for h in hits]\n",
    "        hitslen = len(hits)\n",
    "        qids, ranks = [qid] * hitslen, np.arange(1,hitslen+1), \n",
    "        runs, fixeds = [run] * hitslen, [fixed] * hitslen \n",
    "        df = pd.DataFrame({'topid' : qids, \n",
    "                           'fixed' : fixeds,\n",
    "                           'docid' : docids,\n",
    "                           'rank'  : ranks,\n",
    "                           'score' : scores,\n",
    "                           'runid' : runs})\n",
    "        #duplicates appear, drop them except first\n",
    "        df = df.drop_duplicates(subset='docid', keep='first')\n",
    "        return df\n",
    "    \n",
    "def all_rankings(qrys, run='BM25run', runlen=1000):\n",
    "    frames = []\n",
    "    for qry in tqdm(qrys):\n",
    "        df = retrieve_ranking(qry, run=run, runlen=runlen)\n",
    "        frames.append(df)\n",
    "    return pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trec(run, qrl):\n",
    "    te = 'trec_eval.9.0/trec_eval'\n",
    "    trec = subprocess.run([te, '-q', '-m', 'all_trec', qrl, run], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    #MEAN AVERAGE PREICISON\n",
    "    map_re = re.compile('\\smap\\s*\\tall\\t(\\d.+)')\n",
    "    mr = re.findall(map_re, trec)\n",
    "\n",
    "    #MAP at cutoffs {5,10,20}\n",
    "    map_5_re = re.compile('\\smap_cut_5\\s*\\tall\\t(\\d.+)')\n",
    "    mr5 = re.findall(map_5_re, trec)\n",
    "\n",
    "    map_10_re = re.compile('\\smap_cut_10\\s*\\tall\\t(\\d.+)')\n",
    "    mr10 = re.findall(map_10_re, trec)\n",
    "\n",
    "    map_20_re = re.compile('\\smap_cut_20\\s*\\tall\\t(\\d.+)')\n",
    "    mr20 = re.findall(map_20_re, trec)\n",
    "    \n",
    "    return mr, mr5, mr10, mr20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trec(mr, mr5, mr10, mr20):\n",
    "    print('MAP:        ' +str(mr[0]))\n",
    "    print('MAP_CUT_5:  '+str(mr5[0]))\n",
    "    print('MAP_CUT_10: ' +str(mr10[0]))\n",
    "    print('MAP_CUT_20: '+str(mr20[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(qry, we, v=3, dim=300):\n",
    "    cent = np.zeros(dim)\n",
    "    qid, qs = qry\n",
    "    qs = qs.split()\n",
    "    #build the vector representation of the query\n",
    "    for q in qs:\n",
    "        try:\n",
    "            vec = we.get_vector(q.lower())\n",
    "            cent += vec\n",
    "        except:\n",
    "            continue\n",
    "    #get v similar words to vector, and append them to query\n",
    "    v = v + len(qs)\n",
    "    sim = we.similar_by_vector(cent, topn=v)\n",
    "    query_exp = [t for t,s in sim[len(qs):v]]\n",
    "    res = qs + query_exp\n",
    "    res = ' '.join(res)\n",
    "    res = unidecode.unidecode(res)\n",
    "    return (qid,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(qry, we, v=3, n=5, dim=300, comb='sum'):\n",
    "    qid, qs = qry\n",
    "    qs = qs.split()\n",
    "    scores, d = [], {}\n",
    "    \n",
    "    #create the top n lists for each query term\n",
    "    #conversion to probabilities skipped\n",
    "    for q in qs:\n",
    "        parens = '(){}<>'\n",
    "        reg = re.compile('[%s]' % parens)\n",
    "        q = reg.sub('', q)\n",
    "        try:\n",
    "            vec = we.get_vector(q.lower())\n",
    "            sim = we.similar_by_vector(vec, topn=n+1)\n",
    "           # res = [k for k,v in sim][1:]\n",
    "            scores.append(sim)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    for s in scores:\n",
    "            for k,val in s[1:]:\n",
    "                try:\n",
    "                    if comb == 'sum':\n",
    "                        d[k] += val\n",
    "                    if comb == 'max':\n",
    "                        if d[k] < val:\n",
    "                            d[k] = val\n",
    "                except:\n",
    "                    d[k] = val\n",
    "    \n",
    "    tops = (sorted(d.items(), key = lambda x: int(x[1]), reverse  = True))\n",
    "    top = [k for k,v in tops][:v]\n",
    "    qry = qs + top\n",
    "    #qry = list(set(qry))  #removes duplicates, but does not preserve order\n",
    "    qry = ' '.join(qry)\n",
    "    qry = unidecode.unidecode(qry)\n",
    "    return (qid,qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency-weighted semantic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df, column):\n",
    "    #turn to lower case\n",
    "    df[column] = df[column].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    #throw away some punctuation \n",
    "    df[column] = df[column].str.replace('[^\\w\\s]','')\n",
    "    #throw away stop words\n",
    "    stop = stopwords.words('english')\n",
    "    #outcomment next line for production\n",
    "    extra_words = ['br', 'text', 'bfn', 'language', 'article', 'date', 'headline']\n",
    "    stop += extra_words\n",
    "    df[column] = df[column].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    df[column] = df[column].apply(lambda x: x[:].split(' '))\n",
    "    return df\n",
    "\n",
    "#retrieves runlen initial rankings using basic BM25\n",
    "def retrieve_init(inp, runlen=1000):\n",
    "    qid, qry = inp\n",
    "    hits = searcher.search(JString(qry), runlen)\n",
    "    conts, docids = [h.content for h in hits], [h.docid for h in hits] \n",
    "    df = pd.DataFrame({'cont' : conts, 'docids' : docids, 'qryid': qid})\n",
    "    df = preprocess_text(df, 'cont')\n",
    "        #docs.append(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saliency-weighted semantic network\n",
    "def get_swsn(inp, we, runid, b=0.75, k1=1.2, fixed='Q0', runlen=1000, ranks=1):\n",
    "    \n",
    "    #unpack inputs\n",
    "    qid, ss = inp\n",
    "    ss = ss.split()\n",
    "    qid = [qid] * runlen\n",
    "\n",
    "    rank_init = retrieve_init(inp, runlen=1000)\n",
    "    corpus = Dictionary(rank_init['cont'].values)\n",
    "    \n",
    "    #get the average document length, and precompute some values for loop optimization\n",
    "    avgsl = int(np.mean(np.array([len(x) for x in rank_init['cont'].values])))\n",
    "    kp1, bm1, bavgsl = k1+1, 1-b, b * avgsl\n",
    "    scores = []\n",
    "    \n",
    "    #loop over each document in initial rankings\n",
    "    for sl in tqdm(rank_init['cont'].values):\n",
    "        score = 0\n",
    "        #loop over each word in the document\n",
    "        for w in sl:\n",
    "            sem = 0\n",
    "            tmp_list = []\n",
    "            #loop over each word in the query\n",
    "            for wprime in ss:\n",
    "                try:\n",
    "                    tmp = we.similarity(w, wprime.lower())\n",
    "                except:\n",
    "                    tmp = 0\n",
    "                tmp_list.append(tmp)\n",
    "            sem = max(tmp_list) \n",
    "            try:\n",
    "                tok = corpus.token2id[w]\n",
    "                dfs = corpus.dfs[tok]\n",
    "            except:\n",
    "                dfs = 0\n",
    "            idf = np.log((corpus.num_docs/dfs))\n",
    "            num = sem * kp1\n",
    "            denom = sem + (k1 * (bm1 + bavgsl * len(ss)))\n",
    "            score += idf*(num/denom)\n",
    "        scores.append(score)\n",
    "    #sort the scores and docids\n",
    "    npscores = np.array(scores)\n",
    "    sort_idx = np.argsort(npscores)\n",
    "    sort_scores = np.sort(npscores)\n",
    "    doc_ids = rank_init['docids'].values\n",
    "    sort_docids = np.array(doc_ids)[sort_idx]       \n",
    "    \n",
    "    #return a single df for a single query, ready to be concat to trec_evals texts\n",
    "    df = pd.DataFrame({'qryids' : qid, \n",
    "                       'fixed' : fixed, \n",
    "                       'docids' : sort_docids[::-1], \n",
    "                       'ranks' : ranks,\n",
    "                       'scores': sort_scores[::-1],\n",
    "                       'run': runid})\n",
    "    return df\n",
    "\n",
    "\n",
    "def swsn(qrys, we, runlen=1000, runid='SWSN', b = 0.75, k1=1.2, fixed='Q0'):\n",
    "    dfs = []\n",
    "    #these are exactly the same for each run, so precompute them to avoid doing it inside loops\n",
    "    runid_list = [runid] * runlen\n",
    "    fixed_list = [fixed] * runlen\n",
    "    ranks_list = np.arange(1,runlen+1)\n",
    "    for qry in tqdm(qrys):\n",
    "        df = get_swsn(qry, we, runid=runid_list, fixed=fixed_list, ranks=ranks_list)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main entry function for the 3 ranking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function, wrapper for the 3 different ranking functions\n",
    "def ad_hoc_retrieval(qrys, \n",
    "                     we, \n",
    "                     k1=1.2, \n",
    "                     b=0.75, \n",
    "                     runlen=1000, \n",
    "                     mode='BM25', \n",
    "                     p=False,\n",
    "                     v=3,\n",
    "                     n=5,\n",
    "                     comb='sum',\n",
    "                     dim=300):\n",
    "    \n",
    "    searcher.setBM25Similarity(k1,b)\n",
    "    qrl = 'qrels.robust2004.txt'\n",
    "    \n",
    "    if mode == 'BM25':\n",
    "        path = 'BM25run.txt'\n",
    "        df = all_rankings(qrys, runlen=runlen)\n",
    "    \n",
    "    elif mode == 'centroid':\n",
    "        path = 'Assignment2/centroidrun.txt'\n",
    "        exp_qrys = [centroid(qry, wv) for qry in tqdm(qrys)]\n",
    "        df = all_rankings(exp_qrys,runlen=runlen)\n",
    "        \n",
    "    elif mode == 'fusion':\n",
    "        if comb == 'sum':\n",
    "            path = 'Assignment2/fusion_sumrun.txt'\n",
    "        elif comb == 'max':\n",
    "            path = 'Assignment2/fusion_maxrun.txt'\n",
    "        else:\n",
    "            print('Comb option for fusion not supported. Choose between \\'sum\\ and \\'max\\'')\n",
    "        exp_qrys = [fusion(qry, wv, v=v, n=n, comb=comb) for qry in tqdm(qrys)]\n",
    "        df = all_rankings(exp_qrys, runlen=runlen)\n",
    "        \n",
    "    elif mode == 'swsn':\n",
    "        path = 'Assignment2/swsnrun.txt'\n",
    "        df = swsn(qrys, wv, runlen=runlen, b=b, k1=k1)\n",
    "    \n",
    "    else:\n",
    "        print('Mode not supported')\n",
    "        return 0\n",
    "    \n",
    "    df.to_csv(path, sep=' ', index=False, header=False)\n",
    "    mr, mr5, mr10, mr20 = trec(path, qrl)\n",
    "    if p:\n",
    "        print_trec(mr, mr5, mr10, mr20)\n",
    "    return mr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37b52b285be4c1fa336f761b11f9afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97413c36df9463ba61f3e3ac3d5d0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c701c6962c4614a18d6b91def1f4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b277c0302cf4616b414059326bdeaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['0.0630']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swsn_run = ad_hoc_retrieval(qrys[:3], wv, mode='swsn', runlen=1000, b=0.75, k1=1.2, p=True) \n",
    "swsn_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19080a9bd83647bbb346cace20e36fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb3bd53fe31442d9cc9899d85e87a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:        0.1393\n",
      "MAP_CUT_5:  0.0387\n",
      "MAP_CUT_10: 0.0579\n",
      "MAP_CUT_20: 0.0762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.1393']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_sum = ad_hoc_retrieval(qrys, wv, mode ='fusion', comb='max', v=3, n=5, p=True)\n",
    "fusion_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abea10d486c45eaa2f0b1f88718e1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91e8791153b4373bb8323ffb44dd7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:        0.1570\n",
      "MAP_CUT_5:  0.0459\n",
      "MAP_CUT_10: 0.0654\n",
      "MAP_CUT_20: 0.0879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.1570']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cent = ad_hoc_retrieval(qrys, wv, mode='centroid', p=True)\n",
    "cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d77ea28f464e16a59df6169e3c8eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAP:        0.2362\n",
      "MAP_CUT_5:  0.0712\n",
      "MAP_CUT_10: 0.1054\n",
      "MAP_CUT_20: 0.1408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.2362']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr = ad_hoc_retrieval(qrys, wv, p=True)\n",
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
