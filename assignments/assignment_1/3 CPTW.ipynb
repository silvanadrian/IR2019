{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextually Propagated Term Weights for Document Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load reuters training/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for line in file:\n",
    "        splitted = line.split()\n",
    "        labels.append(splitted[0])\n",
    "        words = \" \".join(splitted[1:])\n",
    "        data.append(words)\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/reuters/r8-train-all-terms.txt') as f:\n",
    "    train_file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  champion products ch approves stock split cham...  earn\n",
       "1  computer terminal systems cpml completes sale ...   acq\n",
       "2  cobanco inc cbco year net shr cts vs dlrs net ...  earn\n",
       "3  am international inc am nd qtr jan oper shr lo...  earn\n",
       "4  brown forman inc bfd th qtr net shr one dlr vs...  earn"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training data\n",
    "train_data,train_labels = read_data(train_file)\n",
    "train_data = pd.concat([pd.DataFrame(train_data, columns=['text']), \n",
    "                        pd.DataFrame(train_labels, columns=['label'])], \n",
    "                       axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/reuters/r8-test-all-terms.txt') as f:\n",
    "    test_file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage from u s japan rif...</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>china daily says vermin eat pct grain stocks a...</td>\n",
       "      <td>grain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian foreign ship ban ends but nsw ports...</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sumitomo bank aims at quick recovery from merg...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amatil proposes two for five bonus share issue...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  asian exporters fear damage from u s japan rif...  trade\n",
       "1  china daily says vermin eat pct grain stocks a...  grain\n",
       "2  australian foreign ship ban ends but nsw ports...   ship\n",
       "3  sumitomo bank aims at quick recovery from merg...    acq\n",
       "4  amatil proposes two for five bonus share issue...   earn"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading test data\n",
    "test_data, test_labels = read_data(test_file)\n",
    "test_data = pd.concat([pd.DataFrame(test_data, columns=['text']), \n",
    "                        pd.DataFrame(test_labels, columns=['label'])], \n",
    "                       axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  champion products ch approves stock split cham...  earn\n",
       "1  computer terminal systems cpml completes sale ...   acq\n",
       "2  cobanco inc cbco year net shr cts vs dlrs net ...  earn\n",
       "3  am international inc am nd qtr jan oper shr lo...  earn\n",
       "4  brown forman inc bfd th qtr net shr one dlr vs...  earn"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge test / training data\n",
    "all_data = pd.concat([train_data,test_data],axis=0)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(train,test):\n",
    "    cv = CountVectorizer()\n",
    "    x_train = cv.fit_transform(train)\n",
    "    tfidf = TfidfTransformer() \n",
    "    train_tfidf = tfidf.fit_transform(x_train)\n",
    "    x_test = cv.transform(test)\n",
    "    x_test_tfidf = tfidf.transform(x_test)\n",
    "    return (train_tfidf,x_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15587"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = [w for row in all_data['text'].values for w in row.split() if w in model.vocab]\n",
    "unique_words = {words for words in all_words}\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_sims()\n",
    "def unique_words_model(model, unique_words):\n",
    "    new_vectors = []\n",
    "    new_vocab = {}\n",
    "    new_index2entity = []\n",
    "    new_vectors_norm = []\n",
    "\n",
    "    for idx in range(len(model.vocab)):\n",
    "        word = model.index2entity[idx]\n",
    "        vec = model.vectors[idx]\n",
    "        vocab = model.vocab[word]\n",
    "        vec_norm = model.vectors_norm[idx]\n",
    "        if word in unique_words:\n",
    "            vocab.index = len(new_index2entity)\n",
    "            new_index2entity.append(word)\n",
    "            new_vocab[word] = vocab\n",
    "            new_vectors.append(vec)\n",
    "            new_vectors_norm.append(vec_norm)\n",
    "\n",
    "    model.vocab = new_vocab\n",
    "    model.vectors = np.array(new_vectors)\n",
    "    model.index2entity = np.array(new_index2entity)\n",
    "    model.index2word = np.array(new_index2entity)\n",
    "    model.vectors_norm = np.array(new_vectors_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_model(model, unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix():\n",
    "    return cosine_similarity(model.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cptw(document, similarities, t = 0.8):\n",
    "    result = np.zeros(len(model.vocab))\n",
    "    for idx in range(len(model.vocab)):\n",
    "        word = model.index2entity[idx]\n",
    "        # frq would be 0 so cptw would also be 0\n",
    "        if word in document.split():\n",
    "            df = pd.DataFrame(similarities[idx], columns=[\"cossim\"])\n",
    "            df = df[df[\"cossim\"] > t] # get all words which are more similar then threshold\n",
    "            df['word'] = df.apply(lambda row: model.index2entity[row.name], axis=1)\n",
    "            df['gamma'] = df.apply(lambda row: document.split().count(row.word)*row.cossim, axis=1)\n",
    "            gamma = df['gamma'].sum()\n",
    "            cos_sims = df['cossim'].sum()\n",
    "            alpha_j = 1 / cos_sims\n",
    "            result[idx] = alpha_j * gamma\n",
    "        else:\n",
    "            result[idx] = 0.0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 80% training, 20% test\n",
    "labels = all_data['label'].values\n",
    "texts = all_data['text'].values\n",
    "X_data_train, X_data_test, y_data_train, y_data_test = train_test_split(texts, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = similarity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_parameters = list(range(1,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF IDF\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "X = X_data_train\n",
    "y = y_data_train\n",
    "kf.get_n_splits(X)\n",
    "tf_idf_scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        for k in k_parameters:\n",
    "            train, test = tf_idf(X_train,X_test)\n",
    "            clf = KNeighborsClassifier(k,weights='distance',n_jobs=30)\n",
    "            clf.fit(train, y_train)\n",
    "\n",
    "            tf_idf_scores.append((accuracy_score(y_test, clf.predict(test)),k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tf_idf_scores = sorted(tf_idf_scores, key=lambda tup: tup[0], reverse=True)\n",
    "_, best_k = sorted_tf_idf_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro: 0.8449271132860058\n",
      "micro: 0.9263843648208469\n",
      "accuracy: 0.9263843648208469\n"
     ]
    }
   ],
   "source": [
    "# run on whole train and then test_data\n",
    "train, test = tf_idf(X_data_train,X_data_test)\n",
    "clf = KNeighborsClassifier(best_k,weights='distance',n_jobs=30)\n",
    "clf.fit(train, y_data_train)\n",
    "print(\"macro:\", f1_score(y_data_test, clf.predict(test), average='macro'))\n",
    "print(\"micro:\",f1_score(y_data_test, clf.predict(test), average='micro'))\n",
    "print(\"accuracy:\",accuracy_score(y_data_test, clf.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPTW experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_parameters = list(range(1,3))\n",
    "tau_parameters = [0.8,0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 1\n",
      "0.9 1\n",
      "0.8 2\n",
      "0.9 2\n",
      "0.8 1\n",
      "0.9 1\n",
      "0.8 2\n",
      "0.9 2\n",
      "0.8 1\n",
      "0.9 1\n",
      "0.8 2\n",
      "0.9 2\n",
      "0.8 1\n",
      "0.9 1\n",
      "0.8 2\n",
      "0.9 2\n",
      "0.8 1\n",
      "0.9 1\n",
      "0.8 2\n",
      "0.9 2\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "X = X_data_train[:30]\n",
    "y = y_data_train[:30]\n",
    "kf.get_n_splits(X)\n",
    "cptw_scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    for k in k_parameters:\n",
    "        for t in tau_parameters:\n",
    "            print(t,k)\n",
    "            train_scores = []\n",
    "            for document in X_train:\n",
    "                train_scores.append(cptw(document, similarities,t=t))\n",
    "\n",
    "            test_scores = []\n",
    "            for document in X_test:\n",
    "                test_scores.append(cptw(document, similarities,t=t))\n",
    "\n",
    "            clf = KNeighborsClassifier(k,weights='distance',n_jobs=40)\n",
    "            clf.fit(train_scores, y_train)\n",
    "            acc = accuracy_score(y_test, clf.predict(test_scores))\n",
    "            cptw_scores.append((acc,k,t))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cptw_scores = sorted(cptw_scores, key=lambda tup: tup[0], reverse=True)\n",
    "_, best_k_cp, best_t_cp = sorted_cptw_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.65\n",
      "macro: 0.22979797979797978\n",
      "micro: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "for document in X_data_train[:100]:\n",
    "    train_scores.append(cptw(document, similarities,t=best_t_cp))\n",
    "\n",
    "test_scores = []\n",
    "for document in X_data_test[:20]:\n",
    "    test_scores.append(cptw(document, similarities,t=best_t_cp))\n",
    "\n",
    "clf = KNeighborsClassifier(best_k_cp,weights='distance',n_jobs=40)\n",
    "clf.fit(train_scores, y_data_train[:100])\n",
    "\n",
    "print(\"accuracy:\", accuracy_score(y_data_test[:20], clf.predict(test_scores)))\n",
    "print(\"macro:\", f1_score(y_data_test[:20], clf.predict(test_scores), average='macro'))\n",
    "print(\"micro:\",f1_score(y_data_test[:20], clf.predict(test_scores), average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
